{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for running in collab, sagemaker etc.\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/studio-lab-user/Generative_Models_for_CERN_Fast_Simulations/utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 08:40:25.436293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-28 08:40:25.436358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-28 08:40:25.436367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "re6ywGTYfdzE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, decomposition, manifold, preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, train_test_split\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import time\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.compat.v1.keras.layers import Input, Dense, LeakyReLU, Conv2D, MaxPooling2D, UpSampling2D,  Concatenate\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.compat.v1.keras.layers import Dropout,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, logcosh\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "import pandas as pd\n",
    "from utils import sum_channels_parallel as sum_channels_parallel\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_EXPERIMENT_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CtnTQjy0Q05",
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9tDJ602Bolmd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:  (48714, 56, 30) max: 678.0\n",
      "Loaded cond:  (48714, 12) max: 7000.0 min: -7000.0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle('../../data/data_proton_photonsum_15_2133.pkl')\n",
    "print('Loaded: ',  data.shape, \"max:\", data.max())\n",
    "\n",
    "# Data containing particle conditional data from particle having responses with proton photon sum in interval [70, 2312] without taking into consideration photon sums of neutron responses.\n",
    "data_cond = pd.read_pickle('../../data/data_cond_photonsum_15_2133_15_3273.pkl')\n",
    "print('Loaded cond: ',  data_cond.shape, \"max:\",data_cond.values.max(), \"min:\",data_cond.values.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate min max proton sum\n",
    "photon_sum_proton_min, photon_sum_proton_max = data_cond.proton_photon_sum.min(), data_cond.proton_photon_sum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Energy', 'Vx', 'Vy', 'Vz', 'Px', 'Py', 'Pz', 'mass', 'charge'], dtype='object'),\n",
       " 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cond.drop(columns=['proton_photon_sum', 'neutron_photon_sum', 'Pdg'], inplace=True)\n",
    "data_cond.columns, len(data_cond.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Energy</th>\n",
       "      <th>Vx</th>\n",
       "      <th>Vy</th>\n",
       "      <th>Vz</th>\n",
       "      <th>Px</th>\n",
       "      <th>Py</th>\n",
       "      <th>Pz</th>\n",
       "      <th>mass</th>\n",
       "      <th>charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3192.38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.022422</td>\n",
       "      <td>-0.182957</td>\n",
       "      <td>-3192.38</td>\n",
       "      <td>939.565413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3961.55</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.076487</td>\n",
       "      <td>0.179845</td>\n",
       "      <td>3961.55</td>\n",
       "      <td>938.272081</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2770.10</td>\n",
       "      <td>1.861170e-17</td>\n",
       "      <td>2.517190e-17</td>\n",
       "      <td>-1.689330e-13</td>\n",
       "      <td>0.305187</td>\n",
       "      <td>0.412760</td>\n",
       "      <td>-2770.10</td>\n",
       "      <td>497.611000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3195.12</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.560528</td>\n",
       "      <td>-0.149980</td>\n",
       "      <td>3195.11</td>\n",
       "      <td>938.272081</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1714.07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.457768</td>\n",
       "      <td>0.145639</td>\n",
       "      <td>-1714.07</td>\n",
       "      <td>939.565413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Energy            Vx            Vy            Vz        Px        Py  \\\n",
       "0  3192.38  0.000000e+00  0.000000e+00  0.000000e+00  0.022422 -0.182957   \n",
       "1  3961.55  0.000000e+00  0.000000e+00  0.000000e+00 -0.076487  0.179845   \n",
       "2  2770.10  1.861170e-17  2.517190e-17 -1.689330e-13  0.305187  0.412760   \n",
       "3  3195.12  0.000000e+00  0.000000e+00  0.000000e+00  0.560528 -0.149980   \n",
       "4  1714.07  0.000000e+00  0.000000e+00  0.000000e+00  0.457768  0.145639   \n",
       "\n",
       "        Pz        mass  charge  \n",
       "0 -3192.38  939.565413     0.0  \n",
       "1  3961.55  938.272081     1.0  \n",
       "2 -2770.10  497.611000     0.0  \n",
       "3  3195.11  938.272081     1.0  \n",
       "4 -1714.07  939.565413     0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cond.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment DIR:  experiments/gan_15_2133_28_03_2023_08_40\n"
     ]
    }
   ],
   "source": [
    "DATE_STR = datetime.now().strftime(\"%d_%m_%Y_%H_%M\")\n",
    "\n",
    "NAME = \"gan\"\n",
    "\n",
    "wandb_run_name = f\"{int(photon_sum_proton_min)}_{int(photon_sum_proton_max)}_{DATE_STR}\"\n",
    "\n",
    "EXPERIMENT_DIR_NAME = f\"experiments/{NAME}_{int(photon_sum_proton_min)}_{int(photon_sum_proton_max)}_{DATE_STR}\"\n",
    "\n",
    "print(\"Experiment DIR: \", EXPERIMENT_DIR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if SAVE_EXPERIMENT_DATA:\n",
    "        isExist = os.path.exists(path)\n",
    "        if not isExist:\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_scales(model_name, scaler_means, scaler_scales):\n",
    "    out_fnm = f\"{model_name}_scales.txt\"\n",
    "    res = \"#means\"\n",
    "    for mean_ in scaler_means:\n",
    "        res += \"\\n\" + str(mean_)\n",
    "    res += \"\\n\\n#scales\"\n",
    "    for scale_ in scaler_scales:\n",
    "        res += \"\\n\" + str(scale_)\n",
    "        \n",
    "    if SAVE_EXPERIMENT_DATA:\n",
    "        filepath = f\"../../{EXPERIMENT_DIR_NAME}/scales/\"\n",
    "        create_dir(filepath)\n",
    "        with open(filepath+out_fnm, mode=\"w\") as f:\n",
    "            f.write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10522,
     "status": "ok",
     "timestamp": 1623609981138,
     "user": {
      "displayName": "Jan Dubiński",
      "photoUrl": "",
      "userId": "04866767089811362617"
     },
     "user_tz": -120
    },
    "id": "g5jISZN7WrvL",
    "outputId": "0cf63b56-f149-4ff0-d3a8-972fd3b7dca3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data max 6.5206213 min 0.0\n"
     ]
    }
   ],
   "source": [
    "data = np.log(data+1)\n",
    "data = np.float32(data)\n",
    "print(\"data max\", data.max(), \"min\", data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1623609981462,
     "user": {
      "displayName": "Jan Dubiński",
      "photoUrl": "",
      "userId": "04866767089811362617"
     },
     "user_tz": -120
    },
    "id": "45N-b-FGn4CO",
    "outputId": "9110f272-5c82-4a0b-dd31-2234414dfe5a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38971, 56, 30) (9743, 56, 30) (38971, 9) (9743, 9)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, = train_test_split(data, data_cond, test_size=0.2, shuffle=False, random_state=42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond max 22.267750474560664 min -37.89385322476621\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "# scale cond datascaler = StandardScaler()\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)\n",
    "print(\"cond max\", y_train.max(), \"min\", y_train.min())\n",
    "\n",
    "#save scales\n",
    "if SAVE_EXPERIMENT_DATA:\n",
    "    save_scales(\"Proton\", scaler.mean_, scaler.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9FMxwgNpn-CU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x_train).batch(batch_size=128)\n",
    "dataset_cond = tf.data.Dataset.from_tensor_slices(y_train).batch(batch_size=128)\n",
    "fake_cond =  tf.data.Dataset.from_tensor_slices(y_train).shuffle(12800).batch(batch_size=128)\n",
    "dataset_with_cond = tf.data.Dataset.zip((dataset,dataset_cond, fake_cond)).shuffle(12800)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(x_test).batch(batch_size=128)\n",
    "val_dataset_cond = tf.data.Dataset.from_tensor_slices(y_test).batch(batch_size=128)\n",
    "val_fake_cond =  tf.data.Dataset.from_tensor_slices(y_test).shuffle(12800).batch(batch_size=128)\n",
    "val_dataset_with_cond = tf.data.Dataset.zip((val_dataset,val_dataset_cond,val_fake_cond)).shuffle(12800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41Ri3GB8n7oI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iFhM4_mYfdzJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1.keras.layers import Input, Dense, LeakyReLU, Conv2D, MaxPooling2D, UpSampling2D,  Concatenate\n",
    "from tensorflow.compat.v1.keras.models import Model\n",
    "from tensorflow.compat.v1.keras.layers import Dense, Reshape, Flatten\n",
    "from tensorflow.compat.v1.keras.layers import Dropout,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy, logcosh\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 19)           0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          5120        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256)         1024        ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 256)          0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4096)         1052672     ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 4096)        16384       ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4096)         0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 4096)         0           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 8, 4, 128)    0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 16, 8, 128)   0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 8, 128)   147584      ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 8, 128)  512         ['conv2d[0][0]']                 \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 8, 128)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 8, 128)   0           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 32, 128)  0          ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 58, 32, 64)   57408       ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 58, 32, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 58, 32, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 58, 32, 64)   0           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 56, 30, 1)    577         ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,281,537\n",
      "Trainable params: 1,272,449\n",
      "Non-trainable params: 9,088\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_img (InputLayer)         [(None, 56, 30, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 54, 28, 32)   320         ['input_img[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 54, 28, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 54, 28, 32)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 54, 28, 32)   0           ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 27, 14, 32)   0           ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 25, 12, 16)   4624        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 25, 12, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 25, 12, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 25, 12, 16)   0           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 16)  0           ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2304)         0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2313)         0           ['flatten[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          296192      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 128)          0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 128)          0           ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           8256        ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64)          256         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 64)           0           ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 1)            65          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 310,417\n",
      "Trainable params: 309,937\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "cond_dim = 9\n",
    "poz_dim = 6\n",
    "\n",
    "############################ generator ############################\n",
    "\n",
    "x = Input(shape=(latent_dim,))\n",
    "cond = Input(shape=(cond_dim,))\n",
    "inputs = Concatenate(axis=1)([x, cond])\n",
    "\n",
    "layer_1 = Dense(128*2)(inputs)\n",
    "layer_1_bd = Dropout(0.2)(BatchNormalization()(layer_1))\n",
    "layer_1_a = LeakyReLU(alpha=0.1)(layer_1_bd)\n",
    "\n",
    "layer_2 = Dense(128*8*4)(layer_1_a)\n",
    "layer_2_bd = Dropout(0.2)(BatchNormalization()(layer_2))\n",
    "layer_2_a = LeakyReLU(alpha=0.1)(layer_2_bd)\n",
    "\n",
    "reshaped = Reshape((8,4,128))(layer_2_a)\n",
    "reshaped_s = UpSampling2D(size=(2,2))(reshaped)\n",
    "\n",
    "conv1 = Conv2D(128, kernel_size=3, padding='same')(reshaped_s)\n",
    "conv1_bd = Dropout(0.2)(BatchNormalization()(conv1))\n",
    "conv1_a = LeakyReLU(alpha=0.1)(conv1_bd)\n",
    "conv1_a_s = UpSampling2D(size=(4,4))(conv1_a)\n",
    "\n",
    "conv2 = Conv2D(64, kernel_size=(7, 1))(conv1_a_s)\n",
    "conv2_bd = Dropout(0.2)(BatchNormalization()(conv2))\n",
    "conv2_a = LeakyReLU(alpha=0.1)(conv2_bd)\n",
    "\n",
    "outputs = Conv2D(1, kernel_size=3, activation='relu')(conv2_a)\n",
    "\n",
    "generator = Model([x, cond], outputs, name='generator')\n",
    "generator.summary()\n",
    "\n",
    "############################ discriminator ############################\n",
    "\n",
    "input_img = Input(shape=[56,30,1],name='input_img')\n",
    "conv1 = Conv2D(32, kernel_size=3)(input_img)\n",
    "conv1_bd = Dropout(0.2)(BatchNormalization()(conv1))\n",
    "conv1_a = LeakyReLU(alpha=0.1)(conv1_bd)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_a)\n",
    "conv2 = Conv2D(16, kernel_size=3)(pool1)\n",
    "conv2_bd = Dropout(0.2)(BatchNormalization()(conv2))\n",
    "conv2_a = LeakyReLU(alpha=0.1)(conv2_bd)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 1))(conv2_a)\n",
    "flat = Flatten()(pool2)\n",
    "cond = Input(shape=(cond_dim,))\n",
    "inputs2 = Concatenate(axis=1)([flat, cond])\n",
    "layer_1 = Dense(128)(inputs2)\n",
    "layer_1_bd = Dropout(0.2)(BatchNormalization()(layer_1))\n",
    "layer_1_a = LeakyReLU(alpha=0.1)(layer_1_bd)\n",
    "layer_2 = Dense(64)(layer_1_a)\n",
    "layer_2_bd = Dropout(0.2)(BatchNormalization()(layer_2))\n",
    "layer_2_a = LeakyReLU(alpha=0.1)(layer_2_bd)\n",
    "outputs = Dense(1, activation='sigmoid')(layer_2_a)\n",
    "\n",
    "discriminator = Model([input_img, cond], outputs, name='discriminator')\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1623609985345,
     "user": {
      "displayName": "Jan Dubiński",
      "photoUrl": "",
      "userId": "04866767089811362617"
     },
     "user_tz": -120
    },
    "id": "UVXZMLDUfdzJ",
    "outputId": "b6cd2a13-46f7-4c7b-d9b6-e6eb0dec7757",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# latent_dim = 10\n",
    "# cond_dim = 10\n",
    "# poz_dim = 6\n",
    "\n",
    "# ############################ generator ############################\n",
    "\n",
    "# x = Input(shape=(latent_dim,))\n",
    "# cond = Input(shape=(cond_dim,))\n",
    "# inputs = Concatenate(axis=1)([x, cond])\n",
    "\n",
    "# layer_1 = Dense(128*2)(inputs)\n",
    "# layer_1_bd = Dropout(0.2)(BatchNormalization()(layer_1))\n",
    "# layer_1_a = LeakyReLU(alpha=0.1)(layer_1_bd)\n",
    "\n",
    "# layer_2 = Dense(128*28*15)(layer_1_a)\n",
    "# layer_2_bd = Dropout(0.2)(BatchNormalization()(layer_2))\n",
    "# layer_2_a = LeakyReLU(alpha=0.1)(layer_2_bd)\n",
    "\n",
    "# reshaped = Reshape((28, 15, 128))(layer_2_a)\n",
    "# # reshaped_s = UpSampling2D()(reshaped)\n",
    "\n",
    "# conv1 = Conv2D(128, kernel_size=1)(reshaped)\n",
    "# conv1_bd = Dropout(0.2)(BatchNormalization()(conv1))\n",
    "# conv1_a = LeakyReLU(alpha=0.1)(conv1_bd)\n",
    "# conv1_a_s = UpSampling2D()(conv1_a)\n",
    "\n",
    "# conv2 = Conv2D(64, kernel_size=1)(conv1_a_s)\n",
    "# conv2_bd = Dropout(0.2)(BatchNormalization()(conv2))\n",
    "# conv2_a = LeakyReLU(alpha=0.1)(conv2_bd)\n",
    "\n",
    "# outputs = Conv2D(1, kernel_size=1,activation='relu')(conv2_a)\n",
    "\n",
    "# generator = Model([x, cond], outputs, name='generator')\n",
    "# generator.summary()\n",
    "\n",
    "# ############################ discriminator ############################\n",
    "\n",
    "# input_img = Input(shape=[56,30,1],name='input_img')\n",
    "# conv1 = Conv2D(32, kernel_size=3)(input_img)\n",
    "# conv1_bd = Dropout(0.2)(BatchNormalization()(conv1))\n",
    "# conv1_a = LeakyReLU(alpha=0.1)(conv1_bd)\n",
    "# pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_a)\n",
    "# conv2 = Conv2D(16, kernel_size=3)(pool1)\n",
    "# conv2_bd = Dropout(0.2)(BatchNormalization()(conv2))\n",
    "# conv2_a = LeakyReLU(alpha=0.1)(conv2_bd)\n",
    "# pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_a)\n",
    "# flat = Flatten()(pool2)\n",
    "# cond = Input(shape=(cond_dim,))\n",
    "\n",
    "# inputs2 = Concatenate(axis=1)([flat, cond])\n",
    "# layer_1 = Dense(128)(inputs2)\n",
    "# layer_1_bd = Dropout(0.2)(BatchNormalization()(layer_1))\n",
    "# layer_1_a = LeakyReLU(alpha=0.1)(layer_1_bd)\n",
    "# layer_2 = Dense(64)(layer_1_a)\n",
    "# layer_2_bd = Dropout(0.2)(BatchNormalization()(layer_2))\n",
    "# layer_2_a = LeakyReLU(alpha=0.1)(layer_2_bd)\n",
    "# outputs = Dense(1, activation='sigmoid')(layer_2_a)\n",
    "\n",
    "# discriminator = Model([input_img, cond], outputs, name='discriminator')\n",
    "# discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "87NnkVJwaCOo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    d_acc_r.update_state(tf.ones_like(real_output), real_output)\n",
    "    d_acc_f.update_state(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss, fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZXwATQ9uaigO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HqTYRo-uki5k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "d_acc_r = keras.metrics.BinaryAccuracy(name=\"d_acc_r\", threshold=0.5)\n",
    "d_acc_f = keras.metrics.BinaryAccuracy(name=\"d_acc_r\", threshold=0.5)\n",
    "g_acc = keras.metrics.BinaryAccuracy(name=\"g_acc_g\", threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yjX97hnkkmlf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(step, fake_output):\n",
    "    g_acc.update_state(tf.ones_like(fake_output), fake_output)\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)# - div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "KhuiPsi6koZY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "I4HsHLgwkurp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "noise_dim = 10\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "START_GENERATING_IMG_FROM_IDX = 20\n",
    "# Seed to reuse for generating samples for comparison during training\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "seed_cond = y_test[START_GENERATING_IMG_FROM_IDX:START_GENERATING_IMG_FROM_IDX+num_examples_to_generate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbedkowski-patrick\u001b[0m (\u001b[33mgenerative-models-cern\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/Generative_Models_for_CERN_Fast_Simulations/notebooks/gan_proton_15_2312/wandb/run-20230328_084031-ub29thym</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations/runs/ub29thym' target=\"_blank\">15_2133_28_03_2023_08_40</a></strong> to <a href='https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations' target=\"_blank\">https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations/runs/ub29thym' target=\"_blank\">https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations/runs/ub29thym</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/generative-models-cern/Generative%20Models%20for%20CERN%20Fast%20Simulations/runs/ub29thym?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f7bc9f3d820>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Generative Models for CERN Fast Simulations\",\n",
    "    name=wandb_run_name,\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"Model\": NAME,\n",
    "    \"dataset\": \"proton_data\",\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"Date\": DATE_STR,\n",
    "    \"Proton_min\": photon_sum_proton_min,\n",
    "    \"Proton_max\": photon_sum_proton_max,\n",
    "    \"Experiment_dir_name\": EXPERIMENT_DIR_NAME\n",
    "    },\n",
    "    tags=[f\"proton_min_{photon_sum_proton_min}\", f\"proton_max_{photon_sum_proton_max}\", \"gan\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rMxBrHhsTDXO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "import pandas as pd\n",
    "from utils import sum_channels_parallel\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "org=np.exp(x_test)-1\n",
    "ch_org = np.array(org).reshape(-1,56,30)\n",
    "ch_org = pd.DataFrame(sum_channels_parallel(ch_org)).values\n",
    "del org\n",
    "\n",
    "\n",
    "def calculate_ws_ch(n_calc):\n",
    "    ws= [0,0,0,0,0]\n",
    "    for j in range(n_calc):\n",
    "        z = np.random.normal(0,1,(x_test.shape[0],10))\n",
    "        z_c = y_test\n",
    "        results = generator.predict([z,z_c])\n",
    "        results = np.exp(results)-1\n",
    "        try:\n",
    "            ch_gen = np.array(results).reshape(-1,56,30)\n",
    "            ch_gen = pd.DataFrame(sum_channels_parallel(ch_gen)).values\n",
    "            for i in range(5):\n",
    "                ws[i] = ws[i] + wasserstein_distance(ch_org[:,i], ch_gen[:,i])\n",
    "            ws =np.array(ws)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            \n",
    "    ws = ws/n_calc\n",
    "    ws_mean = ws.sum()/5\n",
    "    print(\"ws mean\",f'{ws_mean:.2f}', end=\" \")\n",
    "    for n, score in enumerate(ws):\n",
    "        print(\"ch\"+str(n+1),f'{score:.2f}',end=\" \")\n",
    "    return ws_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GmlMSiqCku5_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch,step):\n",
    "    images, cond, noise_cond = batch\n",
    "    step=step\n",
    "    BATCH_SIZE = tf.shape(images)[0]\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator([noise,noise_cond], training=True)\n",
    "\n",
    "        real_output = discriminator([images,cond], training=True)\n",
    "        fake_output = discriminator([generated_images, noise_cond], training=True)\n",
    "\n",
    "        gen_loss = generator_loss(step, fake_output)\n",
    "        real_loss, fake_loss = discriminator_loss(real_output, fake_output)\n",
    "        disc_loss = real_loss + fake_loss\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, real_loss, fake_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "D-wATS0PkvJo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if SAVE_EXPERIMENT_DATA:\n",
    "    filepath_mod = f\"../../{EXPERIMENT_DIR_NAME}/models/\"\n",
    "    create_dir(filepath_mod)\n",
    "\n",
    "history = []\n",
    "def train(dataset, epochs):\n",
    "    experiment_start = time.time()\n",
    "    tf_step = tf.Variable(0, dtype=float)\n",
    "    step=0\n",
    "\n",
    "    # generate first image\n",
    "    generate_and_save_images(generator,\n",
    "                             epochs,\n",
    "                             [seed, seed_cond])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        gen_loss_epoch = []\n",
    "        disc_real_loss_epoch = []\n",
    "        disc_fake_loss_epoch = []\n",
    "        for batch in dataset:\n",
    "            gen_loss, disc_real_loss, disc_fake_loss = train_step(batch,tf_step)\n",
    "            disc_loss = disc_real_loss + disc_fake_loss\n",
    "            \n",
    "            history.append([gen_loss,disc_loss,\n",
    "                100*d_acc_r.result().numpy(),\n",
    "                100*d_acc_f.result().numpy(),\n",
    "                100*g_acc.result().numpy(),\n",
    "                ])\n",
    "            tf_step.assign_add(1)\n",
    "            step = step+1\n",
    "            \n",
    "            gen_loss_epoch.append(gen_loss)\n",
    "            disc_real_loss_epoch.append(disc_real_loss)\n",
    "            disc_fake_loss_epoch.append(disc_fake_loss)\n",
    "            if step % 100 == 0:\n",
    "                print(\"%d [D real acc: %.2f%%] [D fake acc: %.2f%%] [G acc: %.2f%%] \"% (\n",
    "                    step,\n",
    "                    100*d_acc_r.result().numpy(),\n",
    "                    100*d_acc_f.result().numpy(),\n",
    "                    100*g_acc.result().numpy()))\n",
    "\n",
    "        plot = generate_and_save_images(generator,\n",
    "                                 epoch,\n",
    "                                 [seed, seed_cond])\n",
    "        \n",
    "        if SAVE_EXPERIMENT_DATA:\n",
    "            # Save the model every epoch\n",
    "            generator.compile()\n",
    "            discriminator.compile()\n",
    "            generator.save((os.path.join(filepath_mod, \"gen_\"+NAME + \"_\"+ str(epoch) +\".h5\")))\n",
    "            discriminator.save((os.path.join(filepath_mod, \"disc_\"+NAME + \"_\"+ str(epoch) +\".h5\")))\n",
    "            np.savez(os.path.join(filepath_mod, \"history_\"+NAME+\".npz\"),np.array(history))\n",
    "\n",
    "        ws_mean = calculate_ws_ch(min(epoch//5+1,5))\n",
    "        \n",
    "        wandb.log({\n",
    "            'ws_mean': ws_mean,\n",
    "            'gen_loss': np.mean(gen_loss_epoch),\n",
    "            'disc_real_loss': np.mean(disc_real_loss_epoch),\n",
    "            'disc_fake_loss': np.mean(disc_fake_loss_epoch),\n",
    "            'epoch': epoch,\n",
    "            'plot': wandb.Image(plot),\n",
    "            'experiment_time': time.time()-experiment_start\n",
    "        })\n",
    "\n",
    "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CxeGwn7ek8Q-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if SAVE_EXPERIMENT_DATA:\n",
    "    filepath_img = f\"../../{EXPERIMENT_DIR_NAME}/images/\"\n",
    "    create_dir(filepath_img)\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \n",
    "    SUPTITLE_TXT = f\"\\nModel: GAN proton data\" \\\n",
    "               f\"\\nPhotonsum interval: [{photon_sum_proton_min}, {photon_sum_proton_max}]\" \\\n",
    "               f\"\\nEPOCH: {epoch}\"\n",
    "    \n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)  # returns 16 responses\n",
    "\n",
    "    fig, axs = plt.subplots(2, 7, figsize=(15, 5))\n",
    "    fig.suptitle(SUPTITLE_TXT, x=0.1, horizontalalignment='left')\n",
    "\n",
    "    for i in range(0, 14):\n",
    "        if i < 7:\n",
    "            x = x_test[20 + i].reshape(56, 30)\n",
    "        else:\n",
    "            x = predictions[i - 7].numpy().reshape(56, 30)\n",
    "        #x[x<=0]=x.max()*-0.1\n",
    "        im = axs[i // 7, i % 7].imshow(x, cmap='gnuplot')\n",
    "        axs[i // 7, i % 7].axis('off')\n",
    "        fig.colorbar(im, ax=axs[i // 7, i % 7])\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.975])\n",
    "    if SAVE_EXPERIMENT_DATA:\n",
    "        plt.savefig(os.path.join(filepath_img, 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmR61h2W0vxC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [D real acc: 51.17%] [D fake acc: 59.76%] [G acc: 40.24%] \n",
      "200 [D real acc: 59.44%] [D fake acc: 56.53%] [G acc: 43.47%] \n",
      "300 [D real acc: 59.42%] [D fake acc: 54.01%] [G acc: 45.99%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 140.66 ch1 0.05 ch2 10.80 ch3 0.27 ch4 289.06 ch5 403.10 Time for epoch 1 is 38.54326605796814 sec\n",
      "400 [D real acc: 59.59%] [D fake acc: 54.01%] [G acc: 45.99%] \n",
      "500 [D real acc: 60.33%] [D fake acc: 54.41%] [G acc: 45.59%] \n",
      "600 [D real acc: 61.46%] [D fake acc: 55.60%] [G acc: 44.40%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 74.66 ch1 0.19 ch2 40.20 ch3 0.51 ch4 150.80 ch5 181.59 Time for epoch 2 is 26.993642568588257 sec\n",
      "700 [D real acc: 62.61%] [D fake acc: 57.46%] [G acc: 42.54%] \n",
      "800 [D real acc: 63.71%] [D fake acc: 58.86%] [G acc: 41.14%] \n",
      "900 [D real acc: 64.02%] [D fake acc: 59.41%] [G acc: 40.59%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 24.52 ch1 0.02 ch2 6.66 ch3 0.20 ch4 54.52 ch5 61.17 Time for epoch 3 is 27.370929956436157 sec\n",
      "1000 [D real acc: 64.02%] [D fake acc: 59.67%] [G acc: 40.33%] \n",
      "1100 [D real acc: 63.74%] [D fake acc: 59.99%] [G acc: 40.01%] \n",
      "1200 [D real acc: 63.56%] [D fake acc: 60.15%] [G acc: 39.85%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 22.10 ch1 0.03 ch2 11.72 ch3 0.18 ch4 44.79 ch5 53.76 Time for epoch 4 is 27.22740387916565 sec\n",
      "1300 [D real acc: 63.60%] [D fake acc: 60.47%] [G acc: 39.53%] \n",
      "1400 [D real acc: 63.74%] [D fake acc: 60.63%] [G acc: 39.37%] \n",
      "1500 [D real acc: 63.78%] [D fake acc: 60.76%] [G acc: 39.24%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 26.93 ch1 0.03 ch2 11.30 ch3 0.21 ch4 56.01 ch5 67.08 Time for epoch 5 is 27.326308250427246 sec\n",
      "1600 [D real acc: 63.94%] [D fake acc: 60.89%] [G acc: 39.11%] \n",
      "1700 [D real acc: 64.17%] [D fake acc: 61.00%] [G acc: 39.00%] \n",
      "1800 [D real acc: 64.28%] [D fake acc: 61.29%] [G acc: 38.71%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 22.91 ch1 0.03 ch2 10.37 ch3 0.22 ch4 46.82 ch5 57.10 Time for epoch 6 is 30.07285165786743 sec\n",
      "1900 [D real acc: 64.50%] [D fake acc: 61.54%] [G acc: 38.46%] \n",
      "2000 [D real acc: 64.69%] [D fake acc: 61.73%] [G acc: 38.27%] \n",
      "2100 [D real acc: 64.92%] [D fake acc: 62.06%] [G acc: 37.94%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 19.07 ch1 0.02 ch2 9.73 ch3 0.09 ch4 39.53 ch5 45.96 Time for epoch 7 is 29.865745067596436 sec\n",
      "2200 [D real acc: 65.22%] [D fake acc: 62.38%] [G acc: 37.62%] \n",
      "2300 [D real acc: 65.55%] [D fake acc: 62.68%] [G acc: 37.32%] \n",
      "2400 [D real acc: 65.91%] [D fake acc: 62.99%] [G acc: 37.01%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 27.86 ch1 0.03 ch2 11.06 ch3 0.16 ch4 62.54 ch5 65.50 Time for epoch 8 is 29.859535694122314 sec\n",
      "2500 [D real acc: 66.28%] [D fake acc: 63.33%] [G acc: 36.67%] \n",
      "2600 [D real acc: 66.66%] [D fake acc: 63.72%] [G acc: 36.28%] \n",
      "2700 [D real acc: 67.11%] [D fake acc: 64.17%] [G acc: 35.83%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 36.47 ch1 0.04 ch2 11.11 ch3 0.24 ch4 82.19 ch5 88.75 Time for epoch 9 is 30.32846212387085 sec\n",
      "2800 [D real acc: 67.59%] [D fake acc: 64.67%] [G acc: 35.33%] \n",
      "2900 [D real acc: 68.06%] [D fake acc: 65.11%] [G acc: 34.89%] \n",
      "3000 [D real acc: 68.56%] [D fake acc: 65.58%] [G acc: 34.42%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 61.32 ch1 0.03 ch2 9.68 ch3 0.23 ch4 145.31 ch5 151.36 Time for epoch 10 is 29.995425701141357 sec\n",
      "3100 [D real acc: 69.06%] [D fake acc: 66.03%] [G acc: 33.97%] \n",
      "3200 [D real acc: 69.61%] [D fake acc: 66.49%] [G acc: 33.51%] \n",
      "3300 [D real acc: 70.07%] [D fake acc: 67.02%] [G acc: 32.98%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 48.14 ch1 0.03 ch2 9.07 ch3 0.17 ch4 111.32 ch5 120.12 Time for epoch 11 is 32.44087052345276 sec\n",
      "3400 [D real acc: 70.60%] [D fake acc: 67.56%] [G acc: 32.44%] \n",
      "3500 [D real acc: 71.10%] [D fake acc: 68.08%] [G acc: 31.92%] \n",
      "3600 [D real acc: 71.64%] [D fake acc: 68.54%] [G acc: 31.46%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 161.49 ch1 0.03 ch2 9.40 ch3 0.58 ch4 397.06 ch5 400.36 Time for epoch 12 is 32.896063566207886 sec\n",
      "3700 [D real acc: 72.16%] [D fake acc: 69.02%] [G acc: 30.98%] \n",
      "3800 [D real acc: 72.63%] [D fake acc: 69.56%] [G acc: 30.44%] \n",
      "3900 [D real acc: 73.11%] [D fake acc: 70.07%] [G acc: 29.93%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 435.11 ch1 0.03 ch2 9.19 ch3 1.17 ch4 1070.91 ch5 1094.27 Time for epoch 13 is 32.31853675842285 sec\n",
      "4000 [D real acc: 73.58%] [D fake acc: 70.55%] [G acc: 29.45%] \n",
      "4100 [D real acc: 74.05%] [D fake acc: 71.05%] [G acc: 28.95%] \n",
      "4200 [D real acc: 74.52%] [D fake acc: 71.53%] [G acc: 28.47%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 83.05 ch1 0.03 ch2 8.25 ch3 0.22 ch4 200.60 ch5 206.18 Time for epoch 14 is 32.4805862903595 sec\n",
      "4300 [D real acc: 74.98%] [D fake acc: 72.00%] [G acc: 28.00%] \n",
      "4400 [D real acc: 75.41%] [D fake acc: 72.46%] [G acc: 27.54%] \n",
      "4500 [D real acc: 75.85%] [D fake acc: 72.93%] [G acc: 27.07%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 103.87 ch1 0.03 ch2 9.49 ch3 0.50 ch4 251.70 ch5 257.61 Time for epoch 15 is 32.43073129653931 sec\n",
      "4600 [D real acc: 76.26%] [D fake acc: 73.32%] [G acc: 26.68%] \n",
      "4700 [D real acc: 76.68%] [D fake acc: 73.58%] [G acc: 26.42%] \n",
      "4800 [D real acc: 77.08%] [D fake acc: 73.78%] [G acc: 26.22%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 521.14 ch1 0.04 ch2 10.99 ch3 3.65 ch4 1289.99 ch5 1301.04 Time for epoch 16 is 35.33412432670593 sec\n",
      "4900 [D real acc: 77.37%] [D fake acc: 74.09%] [G acc: 25.91%] \n",
      "5000 [D real acc: 77.73%] [D fake acc: 74.40%] [G acc: 25.60%] \n",
      "5100 [D real acc: 78.12%] [D fake acc: 74.77%] [G acc: 25.23%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 8762.69 ch1 0.72 ch2 179.12 ch3 65.03 ch4 21651.72 ch5 21916.84 Time for epoch 17 is 34.966432332992554 sec\n",
      "5200 [D real acc: 78.47%] [D fake acc: 75.11%] [G acc: 24.89%] \n",
      "5300 [D real acc: 78.79%] [D fake acc: 75.51%] [G acc: 24.49%] \n",
      "5400 [D real acc: 79.12%] [D fake acc: 75.90%] [G acc: 24.10%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 29.88 ch1 0.03 ch2 9.93 ch3 0.26 ch4 64.85 ch5 74.32 Time for epoch 18 is 34.973963022232056 sec\n",
      "5500 [D real acc: 79.47%] [D fake acc: 76.26%] [G acc: 23.74%] \n",
      "5600 [D real acc: 79.77%] [D fake acc: 76.61%] [G acc: 23.39%] \n",
      "5700 [D real acc: 80.09%] [D fake acc: 76.99%] [G acc: 23.01%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.90 ch1 0.04 ch2 13.24 ch3 0.41 ch4 116.23 ch5 129.58 Time for epoch 19 is 34.92915916442871 sec\n",
      "5800 [D real acc: 80.40%] [D fake acc: 77.36%] [G acc: 22.64%] \n",
      "5900 [D real acc: 80.69%] [D fake acc: 77.72%] [G acc: 22.28%] \n",
      "6000 [D real acc: 80.99%] [D fake acc: 78.08%] [G acc: 21.92%] \n",
      "6100 [D real acc: 81.28%] [D fake acc: 78.44%] [G acc: 21.56%] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_610/1514722627.py:15: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axs = plt.subplots(2, 7, figsize=(15, 5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 68.86 ch1 0.04 ch2 12.97 ch3 0.40 ch4 160.81 ch5 170.09 Time for epoch 20 is 35.083263874053955 sec\n",
      "6200 [D real acc: 81.56%] [D fake acc: 78.78%] [G acc: 21.22%] \n",
      "6300 [D real acc: 81.84%] [D fake acc: 79.11%] [G acc: 20.89%] \n",
      "6400 [D real acc: 82.11%] [D fake acc: 79.40%] [G acc: 20.60%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.75 ch1 0.04 ch2 12.87 ch3 0.41 ch4 116.06 ch5 129.37 Time for epoch 21 is 37.906517028808594 sec\n",
      "6500 [D real acc: 82.37%] [D fake acc: 79.58%] [G acc: 20.42%] \n",
      "6600 [D real acc: 82.61%] [D fake acc: 79.80%] [G acc: 20.20%] \n",
      "6700 [D real acc: 82.86%] [D fake acc: 80.04%] [G acc: 19.96%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 50.14 ch1 0.04 ch2 12.81 ch3 0.40 ch4 112.24 ch5 125.19 Time for epoch 22 is 37.109697580337524 sec\n",
      "6800 [D real acc: 83.09%] [D fake acc: 80.27%] [G acc: 19.73%] \n",
      "6900 [D real acc: 83.32%] [D fake acc: 80.51%] [G acc: 19.49%] \n",
      "7000 [D real acc: 83.53%] [D fake acc: 80.75%] [G acc: 19.25%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 33.59 ch1 0.03 ch2 9.90 ch3 0.30 ch4 76.81 ch5 80.93 Time for epoch 23 is 37.169893980026245 sec\n",
      "7100 [D real acc: 83.76%] [D fake acc: 80.98%] [G acc: 19.02%] \n",
      "7200 [D real acc: 83.96%] [D fake acc: 81.20%] [G acc: 18.80%] \n",
      "7300 [D real acc: 84.16%] [D fake acc: 81.41%] [G acc: 18.59%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 42.52 ch1 0.03 ch2 8.30 ch3 0.33 ch4 96.38 ch5 107.56 Time for epoch 24 is 37.30118680000305 sec\n",
      "7400 [D real acc: 84.36%] [D fake acc: 81.58%] [G acc: 18.42%] \n",
      "7500 [D real acc: 84.56%] [D fake acc: 81.77%] [G acc: 18.23%] \n",
      "7600 [D real acc: 84.72%] [D fake acc: 81.96%] [G acc: 18.04%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 35.24 ch1 0.04 ch2 8.30 ch3 0.31 ch4 78.73 ch5 88.82 Time for epoch 25 is 37.16094493865967 sec\n",
      "7700 [D real acc: 84.90%] [D fake acc: 82.18%] [G acc: 17.82%] \n",
      "7800 [D real acc: 85.06%] [D fake acc: 82.41%] [G acc: 17.59%] \n",
      "7900 [D real acc: 85.23%] [D fake acc: 82.62%] [G acc: 17.38%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 109.46 ch1 0.04 ch2 18.99 ch3 0.33 ch4 263.26 ch5 264.67 Time for epoch 26 is 37.933419704437256 sec\n",
      "8000 [D real acc: 85.39%] [D fake acc: 82.82%] [G acc: 17.18%] \n",
      "8100 [D real acc: 85.53%] [D fake acc: 83.00%] [G acc: 17.00%] \n",
      "8200 [D real acc: 85.69%] [D fake acc: 83.15%] [G acc: 16.85%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 37.01 ch1 0.02 ch2 7.33 ch3 0.30 ch4 83.57 ch5 93.84 Time for epoch 27 is 37.35180616378784 sec\n",
      "8300 [D real acc: 85.85%] [D fake acc: 83.28%] [G acc: 16.72%] \n",
      "8400 [D real acc: 86.00%] [D fake acc: 83.41%] [G acc: 16.59%] \n",
      "8500 [D real acc: 86.16%] [D fake acc: 83.56%] [G acc: 16.44%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 405.44 ch1 0.08 ch2 22.85 ch3 2.70 ch4 988.66 ch5 1012.89 Time for epoch 28 is 37.285035133361816 sec\n",
      "8600 [D real acc: 86.30%] [D fake acc: 83.72%] [G acc: 16.28%] \n",
      "8700 [D real acc: 86.45%] [D fake acc: 83.87%] [G acc: 16.13%] \n",
      "8800 [D real acc: 86.59%] [D fake acc: 84.02%] [G acc: 15.98%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 787.28 ch1 0.23 ch2 88.87 ch3 3.25 ch4 1943.86 ch5 1900.19 Time for epoch 29 is 37.34563374519348 sec\n",
      "8900 [D real acc: 86.73%] [D fake acc: 84.16%] [G acc: 15.84%] \n",
      "9000 [D real acc: 86.87%] [D fake acc: 84.30%] [G acc: 15.70%] \n",
      "9100 [D real acc: 87.01%] [D fake acc: 84.43%] [G acc: 15.57%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 100269523.17 ch1 2.86 ch2 246691008.20 ch3 1.72 ch4 2973.65 ch5 254653629.45 Time for epoch 30 is 37.47949934005737 sec\n",
      "9200 [D real acc: 87.12%] [D fake acc: 84.57%] [G acc: 15.43%] \n",
      "9300 [D real acc: 87.24%] [D fake acc: 84.72%] [G acc: 15.28%] \n",
      "9400 [D real acc: 87.37%] [D fake acc: 84.87%] [G acc: 15.13%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 1665029.24 ch1 2.07 ch2 7760.25 ch3 8.95 ch4 3187004.54 ch5 5130370.38 Time for epoch 31 is 37.41076064109802 sec\n",
      "9500 [D real acc: 87.50%] [D fake acc: 85.00%] [G acc: 15.00%] \n",
      "9600 [D real acc: 87.63%] [D fake acc: 85.14%] [G acc: 14.86%] \n",
      "9700 [D real acc: 87.74%] [D fake acc: 85.27%] [G acc: 14.73%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 3999.24 ch1 3.25 ch2 1115.20 ch3 17.46 ch4 8833.86 ch5 10026.46 Time for epoch 32 is 38.271167278289795 sec\n",
      "9800 [D real acc: 87.86%] [D fake acc: 85.40%] [G acc: 14.60%] \n",
      "9900 [D real acc: 87.98%] [D fake acc: 85.53%] [G acc: 14.47%] \n",
      "10000 [D real acc: 88.09%] [D fake acc: 85.66%] [G acc: 14.34%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 3604317986.26 ch1 20.46 ch2 6304.58 ch3 78.51 ch4 2511294122.30 ch5 15510289405.44 Time for epoch 33 is 37.54555344581604 sec\n",
      "10100 [D real acc: 88.20%] [D fake acc: 85.79%] [G acc: 14.21%] \n",
      "10200 [D real acc: 88.31%] [D fake acc: 85.92%] [G acc: 14.08%] \n",
      "10300 [D real acc: 88.42%] [D fake acc: 86.05%] [G acc: 13.95%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 774083.58 ch1 1.84 ch2 648.55 ch3 23.54 ch4 1850421.38 ch5 2019322.59 Time for epoch 34 is 37.64680480957031 sec\n",
      "10400 [D real acc: 88.52%] [D fake acc: 86.17%] [G acc: 13.83%] \n",
      "10500 [D real acc: 88.62%] [D fake acc: 86.29%] [G acc: 13.71%] \n",
      "10600 [D real acc: 88.73%] [D fake acc: 86.41%] [G acc: 13.59%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 455.49 ch1 2.69 ch2 956.69 ch3 0.43 ch4 179.91 ch5 1137.72 Time for epoch 35 is 37.393147230148315 sec\n",
      "10700 [D real acc: 88.83%] [D fake acc: 86.52%] [G acc: 13.48%] \n",
      "10800 [D real acc: 88.93%] [D fake acc: 86.64%] [G acc: 13.36%] \n",
      "10900 [D real acc: 89.03%] [D fake acc: 86.76%] [G acc: 13.24%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.29 ch1 0.03 ch2 12.31 ch3 0.41 ch4 115.95 ch5 127.73 Time for epoch 36 is 37.46246552467346 sec\n",
      "11000 [D real acc: 89.11%] [D fake acc: 86.86%] [G acc: 13.14%] \n",
      "11100 [D real acc: 89.20%] [D fake acc: 86.98%] [G acc: 13.02%] \n",
      "11200 [D real acc: 89.29%] [D fake acc: 87.09%] [G acc: 12.91%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.58 ch1 0.04 ch2 11.73 ch3 0.41 ch4 117.08 ch5 128.64 Time for epoch 37 is 37.38857626914978 sec\n",
      "11300 [D real acc: 89.38%] [D fake acc: 87.20%] [G acc: 12.80%] \n",
      "11400 [D real acc: 89.47%] [D fake acc: 87.32%] [G acc: 12.68%] \n",
      "11500 [D real acc: 89.56%] [D fake acc: 87.42%] [G acc: 12.58%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.92 ch1 0.04 ch2 12.70 ch3 0.41 ch4 116.88 ch5 129.56 Time for epoch 38 is 38.266772985458374 sec\n",
      "11600 [D real acc: 89.65%] [D fake acc: 87.53%] [G acc: 12.47%] \n",
      "11700 [D real acc: 89.73%] [D fake acc: 87.64%] [G acc: 12.36%] \n",
      "11800 [D real acc: 89.82%] [D fake acc: 87.74%] [G acc: 12.26%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 54.20 ch1 0.04 ch2 18.48 ch3 0.41 ch4 116.03 ch5 136.02 Time for epoch 39 is 37.389302015304565 sec\n",
      "11900 [D real acc: 89.90%] [D fake acc: 87.84%] [G acc: 12.16%] \n",
      "12000 [D real acc: 89.98%] [D fake acc: 87.94%] [G acc: 12.06%] \n",
      "12100 [D real acc: 90.06%] [D fake acc: 88.00%] [G acc: 12.00%] \n",
      "12200 [D real acc: 90.14%] [D fake acc: 88.07%] [G acc: 11.93%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 40 is 37.20637130737305 sec\n",
      "12300 [D real acc: 90.22%] [D fake acc: 88.15%] [G acc: 11.85%] \n",
      "12400 [D real acc: 90.30%] [D fake acc: 88.23%] [G acc: 11.77%] \n",
      "12500 [D real acc: 90.37%] [D fake acc: 88.32%] [G acc: 11.68%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 41 is 37.04989290237427 sec\n",
      "12600 [D real acc: 90.44%] [D fake acc: 88.41%] [G acc: 11.59%] \n",
      "12700 [D real acc: 90.52%] [D fake acc: 88.49%] [G acc: 11.51%] \n",
      "12800 [D real acc: 90.59%] [D fake acc: 88.58%] [G acc: 11.42%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 42 is 36.763734102249146 sec\n",
      "12900 [D real acc: 90.66%] [D fake acc: 88.66%] [G acc: 11.34%] \n",
      "13000 [D real acc: 90.73%] [D fake acc: 88.74%] [G acc: 11.26%] \n",
      "13100 [D real acc: 90.80%] [D fake acc: 88.82%] [G acc: 11.18%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 43 is 36.765129804611206 sec\n",
      "13200 [D real acc: 90.87%] [D fake acc: 88.91%] [G acc: 11.09%] \n",
      "13300 [D real acc: 90.94%] [D fake acc: 88.99%] [G acc: 11.01%] \n",
      "13400 [D real acc: 91.00%] [D fake acc: 89.07%] [G acc: 10.93%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 44 is 37.02001118659973 sec\n",
      "13500 [D real acc: 91.07%] [D fake acc: 89.14%] [G acc: 10.86%] \n",
      "13600 [D real acc: 91.13%] [D fake acc: 89.22%] [G acc: 10.78%] \n",
      "13700 [D real acc: 91.20%] [D fake acc: 89.30%] [G acc: 10.70%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 45 is 37.76038885116577 sec\n",
      "13800 [D real acc: 91.26%] [D fake acc: 89.37%] [G acc: 10.63%] \n",
      "13900 [D real acc: 91.32%] [D fake acc: 89.45%] [G acc: 10.55%] \n",
      "14000 [D real acc: 91.38%] [D fake acc: 89.52%] [G acc: 10.48%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 46 is 36.78538250923157 sec\n",
      "14100 [D real acc: 91.45%] [D fake acc: 89.59%] [G acc: 10.41%] \n",
      "14200 [D real acc: 91.51%] [D fake acc: 89.67%] [G acc: 10.33%] \n",
      "14300 [D real acc: 91.56%] [D fake acc: 89.74%] [G acc: 10.26%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 47 is 36.68426966667175 sec\n",
      "14400 [D real acc: 91.62%] [D fake acc: 89.81%] [G acc: 10.19%] \n",
      "14500 [D real acc: 91.68%] [D fake acc: 89.88%] [G acc: 10.12%] \n",
      "14600 [D real acc: 91.74%] [D fake acc: 89.94%] [G acc: 10.06%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 54.04 ch1 0.04 ch2 17.65 ch3 0.41 ch4 117.12 ch5 134.99 Time for epoch 48 is 36.77700471878052 sec\n",
      "14700 [D real acc: 91.79%] [D fake acc: 90.01%] [G acc: 9.99%] \n",
      "14800 [D real acc: 91.85%] [D fake acc: 90.07%] [G acc: 9.93%] \n",
      "14900 [D real acc: 91.89%] [D fake acc: 90.14%] [G acc: 9.86%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 106241.26 ch1 0.03 ch2 16.69 ch3 19.63 ch4 177002.20 ch5 354167.76 Time for epoch 49 is 37.17518138885498 sec\n",
      "15000 [D real acc: 91.94%] [D fake acc: 90.20%] [G acc: 9.80%] \n",
      "15100 [D real acc: 91.99%] [D fake acc: 90.26%] [G acc: 9.74%] \n",
      "15200 [D real acc: 92.04%] [D fake acc: 90.32%] [G acc: 9.67%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 50.20 ch1 0.02 ch2 7.56 ch3 0.33 ch4 136.43 ch5 106.66 Time for epoch 50 is 37.18862533569336 sec\n",
      "15300 [D real acc: 92.09%] [D fake acc: 90.37%] [G acc: 9.63%] \n",
      "15400 [D real acc: 92.14%] [D fake acc: 90.41%] [G acc: 9.59%] \n",
      "15500 [D real acc: 92.19%] [D fake acc: 90.46%] [G acc: 9.54%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 82.44 ch1 0.19 ch2 72.01 ch3 0.45 ch4 136.98 ch5 202.57 Time for epoch 51 is 37.553258657455444 sec\n",
      "15600 [D real acc: 92.23%] [D fake acc: 90.51%] [G acc: 9.49%] \n",
      "15700 [D real acc: 92.28%] [D fake acc: 90.57%] [G acc: 9.43%] \n",
      "15800 [D real acc: 92.33%] [D fake acc: 90.62%] [G acc: 9.38%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 96.44 ch1 0.12 ch2 50.82 ch3 0.61 ch4 194.52 ch5 236.14 Time for epoch 52 is 38.44599437713623 sec\n",
      "15900 [D real acc: 92.37%] [D fake acc: 90.67%] [G acc: 9.33%] \n",
      "16000 [D real acc: 92.42%] [D fake acc: 90.72%] [G acc: 9.28%] \n",
      "16100 [D real acc: 92.47%] [D fake acc: 90.78%] [G acc: 9.22%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 58.84 ch1 0.15 ch2 47.29 ch3 0.26 ch4 99.27 ch5 147.23 Time for epoch 53 is 37.31721329689026 sec\n",
      "16200 [D real acc: 92.51%] [D fake acc: 90.83%] [G acc: 9.17%] \n",
      "16300 [D real acc: 92.55%] [D fake acc: 90.87%] [G acc: 9.13%] \n",
      "16400 [D real acc: 92.58%] [D fake acc: 90.91%] [G acc: 9.09%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 83.30 ch1 0.02 ch2 10.29 ch3 0.31 ch4 197.32 ch5 208.54 Time for epoch 54 is 37.30454087257385 sec\n",
      "16500 [D real acc: 92.61%] [D fake acc: 90.94%] [G acc: 9.06%] \n",
      "16600 [D real acc: 92.63%] [D fake acc: 90.98%] [G acc: 9.02%] \n",
      "16700 [D real acc: 92.66%] [D fake acc: 91.03%] [G acc: 8.97%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 37.74 ch1 0.03 ch2 11.85 ch3 0.30 ch4 82.94 ch5 93.59 Time for epoch 55 is 37.34955382347107 sec\n",
      "16800 [D real acc: 92.68%] [D fake acc: 91.06%] [G acc: 8.94%] \n",
      "16900 [D real acc: 92.71%] [D fake acc: 91.11%] [G acc: 8.89%] \n",
      "17000 [D real acc: 92.74%] [D fake acc: 91.15%] [G acc: 8.85%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 32.79 ch1 0.03 ch2 11.22 ch3 0.28 ch4 71.21 ch5 81.22 Time for epoch 56 is 37.23129963874817 sec\n",
      "17100 [D real acc: 92.77%] [D fake acc: 91.18%] [G acc: 8.82%] \n",
      "17200 [D real acc: 92.80%] [D fake acc: 91.22%] [G acc: 8.78%] \n",
      "17300 [D real acc: 92.83%] [D fake acc: 91.27%] [G acc: 8.73%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 147.61 ch1 0.03 ch2 11.67 ch3 1.46 ch4 343.31 ch5 381.59 Time for epoch 57 is 37.308698654174805 sec\n",
      "17400 [D real acc: 92.86%] [D fake acc: 91.30%] [G acc: 8.70%] \n",
      "17500 [D real acc: 92.90%] [D fake acc: 91.34%] [G acc: 8.66%] \n",
      "17600 [D real acc: 92.93%] [D fake acc: 91.37%] [G acc: 8.63%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 73.33 ch1 0.03 ch2 10.82 ch3 0.45 ch4 178.60 ch5 176.73 Time for epoch 58 is 37.26284146308899 sec\n",
      "17700 [D real acc: 92.96%] [D fake acc: 91.41%] [G acc: 8.59%] \n",
      "17800 [D real acc: 92.99%] [D fake acc: 91.45%] [G acc: 8.55%] \n",
      "17900 [D real acc: 93.02%] [D fake acc: 91.49%] [G acc: 8.51%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 53.33 ch1 0.03 ch2 10.07 ch3 0.27 ch4 125.76 ch5 130.50 Time for epoch 59 is 38.596235513687134 sec\n",
      "18000 [D real acc: 93.06%] [D fake acc: 91.53%] [G acc: 8.47%] \n",
      "18100 [D real acc: 93.08%] [D fake acc: 91.57%] [G acc: 8.43%] \n",
      "18200 [D real acc: 93.12%] [D fake acc: 91.61%] [G acc: 8.39%] \n",
      "18300 [D real acc: 93.15%] [D fake acc: 91.65%] [G acc: 8.35%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 26.12 ch1 0.03 ch2 10.37 ch3 0.16 ch4 55.98 ch5 64.06 Time for epoch 60 is 37.25028395652771 sec\n",
      "18400 [D real acc: 93.18%] [D fake acc: 91.69%] [G acc: 8.31%] \n",
      "18500 [D real acc: 93.21%] [D fake acc: 91.73%] [G acc: 8.27%] \n",
      "18600 [D real acc: 93.24%] [D fake acc: 91.77%] [G acc: 8.23%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 33.99 ch1 0.03 ch2 10.49 ch3 0.24 ch4 74.38 ch5 84.83 Time for epoch 61 is 37.30399179458618 sec\n",
      "18700 [D real acc: 93.27%] [D fake acc: 91.81%] [G acc: 8.19%] \n",
      "18800 [D real acc: 93.31%] [D fake acc: 91.85%] [G acc: 8.15%] \n",
      "18900 [D real acc: 93.34%] [D fake acc: 91.89%] [G acc: 8.11%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 26.75 ch1 0.03 ch2 11.52 ch3 0.14 ch4 56.93 ch5 65.15 Time for epoch 62 is 37.320765256881714 sec\n",
      "19000 [D real acc: 93.37%] [D fake acc: 91.92%] [G acc: 8.08%] \n",
      "19100 [D real acc: 93.40%] [D fake acc: 91.96%] [G acc: 8.04%] \n",
      "19200 [D real acc: 93.43%] [D fake acc: 91.99%] [G acc: 8.01%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 23.89 ch1 0.03 ch2 10.92 ch3 0.12 ch4 50.93 ch5 57.44 Time for epoch 63 is 37.29796600341797 sec\n",
      "19300 [D real acc: 93.46%] [D fake acc: 92.02%] [G acc: 7.98%] \n",
      "19400 [D real acc: 93.49%] [D fake acc: 92.04%] [G acc: 7.96%] \n",
      "19500 [D real acc: 93.52%] [D fake acc: 92.07%] [G acc: 7.93%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 232.07 ch1 0.43 ch2 148.18 ch3 1.14 ch4 430.59 ch5 579.99 Time for epoch 64 is 37.412800550460815 sec\n",
      "19600 [D real acc: 93.55%] [D fake acc: 92.10%] [G acc: 7.90%] \n",
      "19700 [D real acc: 93.59%] [D fake acc: 92.14%] [G acc: 7.86%] \n",
      "19800 [D real acc: 93.62%] [D fake acc: 92.17%] [G acc: 7.83%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 692.17 ch1 1.99 ch2 701.97 ch3 2.77 ch4 1023.83 ch5 1730.30 Time for epoch 65 is 37.380610704422 sec\n",
      "19900 [D real acc: 93.65%] [D fake acc: 92.20%] [G acc: 7.80%] \n",
      "20000 [D real acc: 93.68%] [D fake acc: 92.24%] [G acc: 7.76%] \n",
      "20100 [D real acc: 93.71%] [D fake acc: 92.27%] [G acc: 7.73%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 872.19 ch1 1.96 ch2 661.42 ch3 5.98 ch4 1517.00 ch5 2174.60 Time for epoch 66 is 37.44109773635864 sec\n",
      "20200 [D real acc: 93.74%] [D fake acc: 92.31%] [G acc: 7.69%] \n",
      "20300 [D real acc: 93.77%] [D fake acc: 92.34%] [G acc: 7.66%] \n",
      "20400 [D real acc: 93.80%] [D fake acc: 92.38%] [G acc: 7.62%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 251.94 ch1 1.04 ch2 351.63 ch3 0.80 ch4 277.37 ch5 628.86 Time for epoch 67 is 39.032923221588135 sec\n",
      "20500 [D real acc: 93.83%] [D fake acc: 92.41%] [G acc: 7.59%] \n",
      "20600 [D real acc: 93.86%] [D fake acc: 92.44%] [G acc: 7.56%] \n",
      "20700 [D real acc: 93.89%] [D fake acc: 92.48%] [G acc: 7.52%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 562.23 ch1 1.73 ch2 592.41 ch3 2.11 ch4 810.60 ch5 1404.31 Time for epoch 68 is 37.27430009841919 sec\n",
      "20800 [D real acc: 93.91%] [D fake acc: 92.51%] [G acc: 7.49%] \n",
      "20900 [D real acc: 93.94%] [D fake acc: 92.54%] [G acc: 7.46%] \n",
      "21000 [D real acc: 93.97%] [D fake acc: 92.58%] [G acc: 7.42%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 3116.48 ch1 0.26 ch2 5955.39 ch3 0.42 ch4 248.50 ch5 9377.80 Time for epoch 69 is 37.22378873825073 sec\n",
      "21100 [D real acc: 94.00%] [D fake acc: 92.61%] [G acc: 7.39%] \n",
      "21200 [D real acc: 94.02%] [D fake acc: 92.64%] [G acc: 7.36%] \n",
      "21300 [D real acc: 94.05%] [D fake acc: 92.67%] [G acc: 7.33%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 26.88 ch1 0.02 ch2 7.56 ch3 0.26 ch4 60.06 ch5 66.50 Time for epoch 70 is 54.69826912879944 sec\n",
      "21400 [D real acc: 94.07%] [D fake acc: 92.71%] [G acc: 7.29%] \n",
      "21500 [D real acc: 94.09%] [D fake acc: 92.74%] [G acc: 7.26%] \n",
      "21600 [D real acc: 94.11%] [D fake acc: 92.77%] [G acc: 7.23%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 32.88 ch1 0.04 ch2 11.73 ch3 0.27 ch4 70.41 ch5 81.97 Time for epoch 71 is 37.03210759162903 sec\n",
      "21700 [D real acc: 94.14%] [D fake acc: 92.80%] [G acc: 7.20%] \n",
      "21800 [D real acc: 94.16%] [D fake acc: 92.83%] [G acc: 7.17%] \n",
      "21900 [D real acc: 94.19%] [D fake acc: 92.86%] [G acc: 7.14%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 33.16 ch1 0.04 ch2 11.83 ch3 0.25 ch4 70.75 ch5 82.90 Time for epoch 72 is 37.2035276889801 sec\n",
      "22000 [D real acc: 94.21%] [D fake acc: 92.89%] [G acc: 7.11%] \n",
      "22100 [D real acc: 94.23%] [D fake acc: 92.92%] [G acc: 7.08%] \n",
      "22200 [D real acc: 94.25%] [D fake acc: 92.94%] [G acc: 7.06%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 23.38 ch1 0.04 ch2 11.34 ch3 0.18 ch4 50.52 ch5 54.82 Time for epoch 73 is 37.11372470855713 sec\n",
      "22300 [D real acc: 94.27%] [D fake acc: 92.97%] [G acc: 7.03%] \n",
      "22400 [D real acc: 94.30%] [D fake acc: 93.00%] [G acc: 7.00%] \n",
      "22500 [D real acc: 94.32%] [D fake acc: 93.02%] [G acc: 6.98%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 107.31 ch1 0.66 ch2 236.27 ch3 0.23 ch4 74.70 ch5 224.67 Time for epoch 74 is 37.09355926513672 sec\n",
      "22600 [D real acc: 94.35%] [D fake acc: 93.04%] [G acc: 6.96%] \n",
      "22700 [D real acc: 94.37%] [D fake acc: 93.07%] [G acc: 6.93%] \n",
      "22800 [D real acc: 94.39%] [D fake acc: 93.09%] [G acc: 6.91%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 179.92 ch1 1.09 ch2 434.57 ch3 0.30 ch4 86.75 ch5 376.91 Time for epoch 75 is 38.76321196556091 sec\n",
      "22900 [D real acc: 94.42%] [D fake acc: 93.12%] [G acc: 6.88%] \n",
      "23000 [D real acc: 94.44%] [D fake acc: 93.14%] [G acc: 6.86%] \n",
      "23100 [D real acc: 94.47%] [D fake acc: 93.17%] [G acc: 6.83%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 447.57 ch1 2.05 ch2 737.22 ch3 0.98 ch4 378.54 ch5 1119.09 Time for epoch 76 is 37.185797691345215 sec\n",
      "23200 [D real acc: 94.49%] [D fake acc: 93.20%] [G acc: 6.80%] \n",
      "23300 [D real acc: 94.51%] [D fake acc: 93.23%] [G acc: 6.77%] \n",
      "23400 [D real acc: 94.54%] [D fake acc: 93.25%] [G acc: 6.75%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 1857.75 ch1 2.28 ch2 1049.50 ch3 6.18 ch4 3759.30 ch5 4471.47 Time for epoch 77 is 37.17373776435852 sec\n",
      "23500 [D real acc: 94.56%] [D fake acc: 93.28%] [G acc: 6.72%] \n",
      "23600 [D real acc: 94.58%] [D fake acc: 93.30%] [G acc: 6.70%] \n",
      "23700 [D real acc: 94.60%] [D fake acc: 93.33%] [G acc: 6.67%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 304892.28 ch1 56.84 ch2 15729.63 ch3 40.59 ch4 863788.47 ch5 644845.89 Time for epoch 78 is 37.17695212364197 sec\n",
      "23800 [D real acc: 94.63%] [D fake acc: 93.36%] [G acc: 6.64%] \n",
      "23900 [D real acc: 94.65%] [D fake acc: 93.39%] [G acc: 6.61%] \n",
      "24000 [D real acc: 94.67%] [D fake acc: 93.41%] [G acc: 6.59%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 19131.82 ch1 2.54 ch2 942.57 ch3 54.69 ch4 40278.91 ch5 54380.42 Time for epoch 79 is 37.23194980621338 sec\n",
      "24100 [D real acc: 94.69%] [D fake acc: 93.44%] [G acc: 6.56%] \n",
      "24200 [D real acc: 94.71%] [D fake acc: 93.46%] [G acc: 6.54%] \n",
      "24300 [D real acc: 94.73%] [D fake acc: 93.49%] [G acc: 6.51%] \n",
      "24400 [D real acc: 94.75%] [D fake acc: 93.51%] [G acc: 6.49%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 15590171.74 ch1 46.23 ch2 17417.21 ch3 35.94 ch4 40098925.21 ch5 37834434.12 Time for epoch 80 is 37.22098183631897 sec\n",
      "24500 [D real acc: 94.77%] [D fake acc: 93.54%] [G acc: 6.46%] \n",
      "24600 [D real acc: 94.79%] [D fake acc: 93.56%] [G acc: 6.44%] \n",
      "24700 [D real acc: 94.81%] [D fake acc: 93.59%] [G acc: 6.41%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 496.58 ch1 0.04 ch2 12.36 ch3 0.34 ch4 305.59 ch5 2164.55 Time for epoch 81 is 37.34335374832153 sec\n",
      "24800 [D real acc: 94.83%] [D fake acc: 93.61%] [G acc: 6.39%] \n",
      "24900 [D real acc: 94.85%] [D fake acc: 93.64%] [G acc: 6.36%] \n",
      "25000 [D real acc: 94.87%] [D fake acc: 93.66%] [G acc: 6.34%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.12 ch1 0.03 ch2 11.98 ch3 0.40 ch4 115.53 ch5 127.64 Time for epoch 82 is 37.27358055114746 sec\n",
      "25100 [D real acc: 94.89%] [D fake acc: 93.69%] [G acc: 6.31%] \n",
      "25200 [D real acc: 94.91%] [D fake acc: 93.71%] [G acc: 6.29%] \n",
      "25300 [D real acc: 94.93%] [D fake acc: 93.74%] [G acc: 6.26%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.03 ch1 0.04 ch2 12.82 ch3 0.41 ch4 116.97 ch5 129.93 Time for epoch 83 is 37.21364092826843 sec\n",
      "25400 [D real acc: 94.95%] [D fake acc: 93.76%] [G acc: 6.24%] \n",
      "25500 [D real acc: 94.97%] [D fake acc: 93.78%] [G acc: 6.22%] \n",
      "25600 [D real acc: 94.99%] [D fake acc: 93.81%] [G acc: 6.19%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.09 ch1 0.04 ch2 13.05 ch3 0.41 ch4 116.88 ch5 130.07 Time for epoch 84 is 39.01238656044006 sec\n",
      "25700 [D real acc: 95.01%] [D fake acc: 93.83%] [G acc: 6.17%] \n",
      "25800 [D real acc: 95.03%] [D fake acc: 93.86%] [G acc: 6.14%] \n",
      "25900 [D real acc: 95.05%] [D fake acc: 93.88%] [G acc: 6.12%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.03 ch1 0.04 ch2 13.22 ch3 0.41 ch4 116.54 ch5 129.93 Time for epoch 85 is 37.38561463356018 sec\n",
      "26000 [D real acc: 95.07%] [D fake acc: 93.90%] [G acc: 6.10%] \n",
      "26100 [D real acc: 95.09%] [D fake acc: 93.93%] [G acc: 6.07%] \n",
      "26200 [D real acc: 95.10%] [D fake acc: 93.95%] [G acc: 6.05%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.23 ch1 0.04 ch2 13.27 ch3 0.41 ch4 116.99 ch5 130.42 Time for epoch 86 is 37.35456991195679 sec\n",
      "26300 [D real acc: 95.12%] [D fake acc: 93.97%] [G acc: 6.03%] \n",
      "26400 [D real acc: 95.14%] [D fake acc: 93.99%] [G acc: 6.01%] \n",
      "26500 [D real acc: 95.16%] [D fake acc: 94.02%] [G acc: 5.98%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 75.07 ch1 0.03 ch2 37.25 ch3 0.41 ch4 145.13 ch5 192.54 Time for epoch 87 is 37.34872245788574 sec\n",
      "26600 [D real acc: 95.18%] [D fake acc: 94.04%] [G acc: 5.96%] \n",
      "26700 [D real acc: 95.20%] [D fake acc: 94.06%] [G acc: 5.94%] \n",
      "26800 [D real acc: 95.21%] [D fake acc: 94.08%] [G acc: 5.92%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.71 ch1 0.04 ch2 11.82 ch3 0.41 ch4 117.34 ch5 133.94 Time for epoch 88 is 37.209967374801636 sec\n",
      "26900 [D real acc: 95.23%] [D fake acc: 94.11%] [G acc: 5.89%] \n",
      "27000 [D real acc: 95.25%] [D fake acc: 94.13%] [G acc: 5.87%] \n",
      "27100 [D real acc: 95.27%] [D fake acc: 94.15%] [G acc: 5.85%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 51.63 ch1 0.04 ch2 13.25 ch3 0.40 ch4 115.54 ch5 128.93 Time for epoch 89 is 37.20814514160156 sec\n",
      "27200 [D real acc: 95.28%] [D fake acc: 94.17%] [G acc: 5.83%] \n",
      "27300 [D real acc: 95.30%] [D fake acc: 94.19%] [G acc: 5.81%] \n",
      "27400 [D real acc: 95.32%] [D fake acc: 94.21%] [G acc: 5.79%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.28 ch1 0.04 ch2 13.28 ch3 0.41 ch4 117.12 ch5 130.56 Time for epoch 90 is 37.08225727081299 sec\n",
      "27500 [D real acc: 95.33%] [D fake acc: 94.23%] [G acc: 5.77%] \n",
      "27600 [D real acc: 95.35%] [D fake acc: 94.25%] [G acc: 5.75%] \n",
      "27700 [D real acc: 95.37%] [D fake acc: 94.27%] [G acc: 5.73%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 136.69 ch1 0.49 ch2 179.58 ch3 0.49 ch4 162.21 ch5 340.66 Time for epoch 91 is 37.17162585258484 sec\n",
      "27800 [D real acc: 95.38%] [D fake acc: 94.29%] [G acc: 5.71%] \n",
      "27900 [D real acc: 95.40%] [D fake acc: 94.31%] [G acc: 5.69%] \n",
      "28000 [D real acc: 95.42%] [D fake acc: 94.33%] [G acc: 5.67%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 109.03 ch1 0.23 ch2 66.10 ch3 0.80 ch4 205.59 ch5 272.45 Time for epoch 92 is 37.24068522453308 sec\n",
      "28100 [D real acc: 95.43%] [D fake acc: 94.35%] [G acc: 5.65%] \n",
      "28200 [D real acc: 95.45%] [D fake acc: 94.36%] [G acc: 5.64%] \n",
      "28300 [D real acc: 95.46%] [D fake acc: 94.38%] [G acc: 5.62%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 37.32 ch1 0.03 ch2 12.08 ch3 0.28 ch4 81.07 ch5 93.12 Time for epoch 93 is 39.189374923706055 sec\n",
      "28400 [D real acc: 95.47%] [D fake acc: 94.40%] [G acc: 5.60%] \n",
      "28500 [D real acc: 95.49%] [D fake acc: 94.42%] [G acc: 5.58%] \n",
      "28600 [D real acc: 95.50%] [D fake acc: 94.44%] [G acc: 5.56%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 25.65 ch1 0.03 ch2 11.86 ch3 0.20 ch4 52.91 ch5 63.25 Time for epoch 94 is 37.10693669319153 sec\n",
      "28700 [D real acc: 95.51%] [D fake acc: 94.46%] [G acc: 5.54%] \n",
      "28800 [D real acc: 95.53%] [D fake acc: 94.47%] [G acc: 5.53%] \n",
      "28900 [D real acc: 95.54%] [D fake acc: 94.49%] [G acc: 5.51%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 58.75 ch1 0.09 ch2 29.21 ch3 0.41 ch4 121.83 ch5 142.21 Time for epoch 95 is 37.19214940071106 sec\n",
      "29000 [D real acc: 95.56%] [D fake acc: 94.50%] [G acc: 5.50%] \n",
      "29100 [D real acc: 95.57%] [D fake acc: 94.52%] [G acc: 5.48%] \n",
      "29200 [D real acc: 95.59%] [D fake acc: 94.54%] [G acc: 5.46%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 67.59 ch1 0.34 ch2 113.55 ch3 0.26 ch4 74.44 ch5 149.34 Time for epoch 96 is 37.212464332580566 sec\n",
      "29300 [D real acc: 95.60%] [D fake acc: 94.55%] [G acc: 5.45%] \n",
      "29400 [D real acc: 95.62%] [D fake acc: 94.57%] [G acc: 5.43%] \n",
      "29500 [D real acc: 95.63%] [D fake acc: 94.59%] [G acc: 5.41%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 248.53 ch1 1.37 ch2 481.24 ch3 0.52 ch4 170.99 ch5 588.53 Time for epoch 97 is 37.200541257858276 sec\n",
      "29600 [D real acc: 95.65%] [D fake acc: 94.60%] [G acc: 5.40%] \n",
      "29700 [D real acc: 95.66%] [D fake acc: 94.62%] [G acc: 5.38%] \n",
      "29800 [D real acc: 95.68%] [D fake acc: 94.64%] [G acc: 5.36%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 364.55 ch1 2.39 ch2 777.58 ch3 0.43 ch4 149.32 ch5 893.05 Time for epoch 98 is 37.34580659866333 sec\n",
      "29900 [D real acc: 95.69%] [D fake acc: 94.65%] [G acc: 5.35%] \n",
      "30000 [D real acc: 95.70%] [D fake acc: 94.67%] [G acc: 5.33%] \n",
      "30100 [D real acc: 95.72%] [D fake acc: 94.69%] [G acc: 5.31%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 3853.85 ch1 2.71 ch2 1106.57 ch3 18.29 ch4 7640.16 ch5 10501.54 Time for epoch 99 is 37.26596713066101 sec\n",
      "30200 [D real acc: 95.73%] [D fake acc: 94.70%] [G acc: 5.30%] \n",
      "30300 [D real acc: 95.75%] [D fake acc: 94.72%] [G acc: 5.28%] \n",
      "30400 [D real acc: 95.76%] [D fake acc: 94.74%] [G acc: 5.26%] \n",
      "30500 [D real acc: 95.77%] [D fake acc: 94.75%] [G acc: 5.25%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 810.16 ch1 4.88 ch2 1667.86 ch3 1.60 ch4 381.69 ch5 1994.78 Time for epoch 100 is 37.24460220336914 sec\n",
      "30600 [D real acc: 95.79%] [D fake acc: 94.77%] [G acc: 5.23%] \n",
      "30700 [D real acc: 95.80%] [D fake acc: 94.78%] [G acc: 5.22%] \n",
      "30800 [D real acc: 95.81%] [D fake acc: 94.80%] [G acc: 5.20%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 640.38 ch1 4.03 ch2 1475.82 ch3 0.48 ch4 158.89 ch5 1562.68 Time for epoch 101 is 37.255059480667114 sec\n",
      "30900 [D real acc: 95.83%] [D fake acc: 94.82%] [G acc: 5.18%] \n",
      "31000 [D real acc: 95.84%] [D fake acc: 94.83%] [G acc: 5.17%] \n",
      "31100 [D real acc: 95.85%] [D fake acc: 94.85%] [G acc: 5.15%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 3601.00 ch1 1.74 ch2 595.60 ch3 0.41 ch4 149.81 ch5 17257.46 Time for epoch 102 is 39.36021876335144 sec\n",
      "31200 [D real acc: 95.87%] [D fake acc: 94.86%] [G acc: 5.14%] \n",
      "31300 [D real acc: 95.88%] [D fake acc: 94.88%] [G acc: 5.12%] \n",
      "31400 [D real acc: 95.89%] [D fake acc: 94.90%] [G acc: 5.10%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 149777700.75 ch1 0.84 ch2 328.57 ch3 1.38 ch4 2013.08 ch5 748886159.89 Time for epoch 103 is 37.261810064315796 sec\n",
      "31500 [D real acc: 95.91%] [D fake acc: 94.91%] [G acc: 5.09%] \n",
      "31600 [D real acc: 95.92%] [D fake acc: 94.93%] [G acc: 5.07%] \n",
      "31700 [D real acc: 95.93%] [D fake acc: 94.94%] [G acc: 5.06%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 77.56 ch1 0.04 ch2 12.19 ch3 0.34 ch4 128.81 ch5 246.42 Time for epoch 104 is 37.268739461898804 sec\n",
      "31800 [D real acc: 95.94%] [D fake acc: 94.96%] [G acc: 5.04%] \n",
      "31900 [D real acc: 95.95%] [D fake acc: 94.97%] [G acc: 5.03%] \n",
      "32000 [D real acc: 95.97%] [D fake acc: 94.99%] [G acc: 5.01%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 6907.87 ch1 0.04 ch2 9.97 ch3 0.39 ch4 5042.88 ch5 29486.07 Time for epoch 105 is 37.239630460739136 sec\n",
      "32100 [D real acc: 95.98%] [D fake acc: 95.00%] [G acc: 5.00%] \n",
      "32200 [D real acc: 95.99%] [D fake acc: 95.02%] [G acc: 4.98%] \n",
      "32300 [D real acc: 96.00%] [D fake acc: 95.03%] [G acc: 4.97%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 48.62 ch1 0.03 ch2 8.71 ch3 0.39 ch4 112.10 ch5 121.87 Time for epoch 106 is 37.24413299560547 sec\n",
      "32400 [D real acc: 96.02%] [D fake acc: 95.05%] [G acc: 4.95%] \n",
      "32500 [D real acc: 96.03%] [D fake acc: 95.06%] [G acc: 4.94%] \n",
      "32600 [D real acc: 96.04%] [D fake acc: 95.08%] [G acc: 4.92%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 20.57 ch1 0.03 ch2 10.53 ch3 0.23 ch4 43.83 ch5 48.24 Time for epoch 107 is 37.26661133766174 sec\n",
      "32700 [D real acc: 96.05%] [D fake acc: 95.09%] [G acc: 4.91%] \n",
      "32800 [D real acc: 96.06%] [D fake acc: 95.11%] [G acc: 4.89%] \n",
      "32900 [D real acc: 96.07%] [D fake acc: 95.12%] [G acc: 4.88%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 31.26 ch1 0.04 ch2 12.44 ch3 0.31 ch4 65.69 ch5 77.82 Time for epoch 108 is 37.29328632354736 sec\n",
      "33000 [D real acc: 96.08%] [D fake acc: 95.13%] [G acc: 4.87%] \n",
      "33100 [D real acc: 96.09%] [D fake acc: 95.14%] [G acc: 4.86%] \n",
      "33200 [D real acc: 96.10%] [D fake acc: 95.16%] [G acc: 4.84%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 33.59 ch1 0.04 ch2 12.42 ch3 0.33 ch4 71.16 ch5 84.03 Time for epoch 109 is 54.93537664413452 sec\n",
      "33300 [D real acc: 96.11%] [D fake acc: 95.17%] [G acc: 4.83%] \n",
      "33400 [D real acc: 96.12%] [D fake acc: 95.18%] [G acc: 4.82%] \n",
      "33500 [D real acc: 96.13%] [D fake acc: 95.19%] [G acc: 4.81%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 19.99 ch1 0.03 ch2 11.74 ch3 0.24 ch4 38.25 ch5 49.72 Time for epoch 110 is 37.04424691200256 sec\n",
      "33600 [D real acc: 96.14%] [D fake acc: 95.20%] [G acc: 4.80%] \n",
      "33700 [D real acc: 96.15%] [D fake acc: 95.21%] [G acc: 4.79%] \n",
      "33800 [D real acc: 96.15%] [D fake acc: 95.22%] [G acc: 4.78%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 17.68 ch1 0.04 ch2 12.49 ch3 0.10 ch4 32.92 ch5 42.87 Time for epoch 111 is 39.404712200164795 sec\n",
      "33900 [D real acc: 96.16%] [D fake acc: 95.24%] [G acc: 4.76%] \n",
      "34000 [D real acc: 96.17%] [D fake acc: 95.25%] [G acc: 4.75%] \n",
      "34100 [D real acc: 96.18%] [D fake acc: 95.26%] [G acc: 4.74%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 19.14 ch1 0.04 ch2 12.22 ch3 0.15 ch4 36.93 ch5 46.38 Time for epoch 112 is 37.1524498462677 sec\n",
      "34200 [D real acc: 96.19%] [D fake acc: 95.27%] [G acc: 4.73%] \n",
      "34300 [D real acc: 96.20%] [D fake acc: 95.28%] [G acc: 4.72%] \n",
      "34400 [D real acc: 96.21%] [D fake acc: 95.30%] [G acc: 4.70%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 14.49 ch1 0.03 ch2 11.92 ch3 0.15 ch4 25.53 ch5 34.84 Time for epoch 113 is 37.26443839073181 sec\n",
      "34500 [D real acc: 96.22%] [D fake acc: 95.31%] [G acc: 4.69%] \n",
      "34600 [D real acc: 96.23%] [D fake acc: 95.32%] [G acc: 4.68%] \n",
      "34700 [D real acc: 96.24%] [D fake acc: 95.33%] [G acc: 4.67%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 35.19 ch1 0.03 ch2 10.78 ch3 0.27 ch4 76.64 ch5 88.21 Time for epoch 114 is 37.24484038352966 sec\n",
      "34800 [D real acc: 96.25%] [D fake acc: 95.34%] [G acc: 4.66%] \n",
      "34900 [D real acc: 96.25%] [D fake acc: 95.35%] [G acc: 4.65%] \n",
      "35000 [D real acc: 96.26%] [D fake acc: 95.36%] [G acc: 4.64%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 23.77 ch1 0.04 ch2 12.13 ch3 0.23 ch4 47.68 ch5 58.79 Time for epoch 115 is 37.15451502799988 sec\n",
      "35100 [D real acc: 96.27%] [D fake acc: 95.38%] [G acc: 4.62%] \n",
      "35200 [D real acc: 96.28%] [D fake acc: 95.39%] [G acc: 4.61%] \n",
      "35300 [D real acc: 96.29%] [D fake acc: 95.40%] [G acc: 4.60%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 23.61 ch1 0.04 ch2 11.48 ch3 0.18 ch4 50.15 ch5 56.17 Time for epoch 116 is 37.1954402923584 sec\n",
      "35400 [D real acc: 96.30%] [D fake acc: 95.41%] [G acc: 4.59%] \n",
      "35500 [D real acc: 96.31%] [D fake acc: 95.42%] [G acc: 4.58%] \n",
      "35600 [D real acc: 96.32%] [D fake acc: 95.43%] [G acc: 4.57%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 29.95 ch1 0.04 ch2 11.41 ch3 0.21 ch4 64.63 ch5 73.48 Time for epoch 117 is 37.26944446563721 sec\n",
      "35700 [D real acc: 96.33%] [D fake acc: 95.44%] [G acc: 4.56%] \n",
      "35800 [D real acc: 96.34%] [D fake acc: 95.45%] [G acc: 4.55%] \n",
      "35900 [D real acc: 96.34%] [D fake acc: 95.46%] [G acc: 4.54%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 29.15 ch1 0.03 ch2 10.54 ch3 0.25 ch4 63.44 ch5 71.46 Time for epoch 118 is 37.274205684661865 sec\n",
      "36000 [D real acc: 96.35%] [D fake acc: 95.47%] [G acc: 4.53%] \n",
      "36100 [D real acc: 96.36%] [D fake acc: 95.48%] [G acc: 4.52%] \n",
      "36200 [D real acc: 96.37%] [D fake acc: 95.50%] [G acc: 4.50%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 25.53 ch1 0.03 ch2 10.84 ch3 0.23 ch4 55.06 ch5 61.49 Time for epoch 119 is 37.35646367073059 sec\n",
      "36300 [D real acc: 96.38%] [D fake acc: 95.51%] [G acc: 4.49%] \n",
      "36400 [D real acc: 96.39%] [D fake acc: 95.52%] [G acc: 4.48%] \n",
      "36500 [D real acc: 96.40%] [D fake acc: 95.53%] [G acc: 4.47%] \n",
      "36600 [D real acc: 96.41%] [D fake acc: 95.54%] [G acc: 4.46%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 29.22 ch1 0.04 ch2 11.53 ch3 0.18 ch4 66.83 ch5 67.54 Time for epoch 120 is 37.351101875305176 sec\n",
      "36700 [D real acc: 96.41%] [D fake acc: 95.55%] [G acc: 4.45%] \n",
      "36800 [D real acc: 96.42%] [D fake acc: 95.56%] [G acc: 4.44%] \n",
      "36900 [D real acc: 96.43%] [D fake acc: 95.57%] [G acc: 4.43%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 27.76 ch1 0.04 ch2 11.86 ch3 0.25 ch4 59.29 ch5 67.38 Time for epoch 121 is 39.70801377296448 sec\n",
      "37000 [D real acc: 96.44%] [D fake acc: 95.58%] [G acc: 4.42%] \n",
      "37100 [D real acc: 96.44%] [D fake acc: 95.59%] [G acc: 4.41%] \n",
      "37200 [D real acc: 96.45%] [D fake acc: 95.60%] [G acc: 4.40%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 20.79 ch1 0.04 ch2 11.81 ch3 0.20 ch4 43.61 ch5 48.32 Time for epoch 122 is 37.32347059249878 sec\n",
      "37300 [D real acc: 96.46%] [D fake acc: 95.61%] [G acc: 4.39%] \n",
      "37400 [D real acc: 96.47%] [D fake acc: 95.62%] [G acc: 4.38%] \n",
      "37500 [D real acc: 96.47%] [D fake acc: 95.63%] [G acc: 4.37%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 23.32 ch1 0.04 ch2 11.82 ch3 0.21 ch4 49.29 ch5 55.25 Time for epoch 123 is 37.32527947425842 sec\n",
      "37600 [D real acc: 96.48%] [D fake acc: 95.64%] [G acc: 4.36%] \n",
      "37700 [D real acc: 96.49%] [D fake acc: 95.65%] [G acc: 4.35%] \n",
      "37800 [D real acc: 96.50%] [D fake acc: 95.66%] [G acc: 4.34%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 20.81 ch1 0.04 ch2 12.24 ch3 0.21 ch4 40.40 ch5 51.19 Time for epoch 124 is 37.31045651435852 sec\n",
      "37900 [D real acc: 96.50%] [D fake acc: 95.66%] [G acc: 4.34%] \n",
      "38000 [D real acc: 96.51%] [D fake acc: 95.67%] [G acc: 4.33%] \n",
      "38100 [D real acc: 96.52%] [D fake acc: 95.68%] [G acc: 4.32%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 16.03 ch1 0.04 ch2 12.41 ch3 0.16 ch4 27.62 ch5 39.93 Time for epoch 125 is 37.34254455566406 sec\n",
      "38200 [D real acc: 96.53%] [D fake acc: 95.69%] [G acc: 4.31%] \n",
      "38300 [D real acc: 96.53%] [D fake acc: 95.70%] [G acc: 4.30%] \n",
      "38400 [D real acc: 96.54%] [D fake acc: 95.71%] [G acc: 4.29%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 22.87 ch1 0.04 ch2 12.04 ch3 0.19 ch4 48.11 ch5 53.97 Time for epoch 126 is 37.34048867225647 sec\n",
      "38500 [D real acc: 96.55%] [D fake acc: 95.71%] [G acc: 4.29%] \n",
      "38600 [D real acc: 96.55%] [D fake acc: 95.72%] [G acc: 4.28%] \n",
      "38700 [D real acc: 96.56%] [D fake acc: 95.73%] [G acc: 4.27%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 30.05 ch1 0.03 ch2 10.80 ch3 0.19 ch4 67.04 ch5 72.18 Time for epoch 127 is 37.364710569381714 sec\n",
      "38800 [D real acc: 96.57%] [D fake acc: 95.74%] [G acc: 4.26%] \n",
      "38900 [D real acc: 96.57%] [D fake acc: 95.75%] [G acc: 4.25%] \n",
      "39000 [D real acc: 96.58%] [D fake acc: 95.76%] [G acc: 4.24%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 79.99 ch1 0.04 ch2 11.86 ch3 0.45 ch4 189.88 ch5 197.73 Time for epoch 128 is 37.35722899436951 sec\n",
      "39100 [D real acc: 96.59%] [D fake acc: 95.77%] [G acc: 4.23%] \n",
      "39200 [D real acc: 96.60%] [D fake acc: 95.78%] [G acc: 4.22%] \n",
      "39300 [D real acc: 96.60%] [D fake acc: 95.79%] [G acc: 4.21%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 20.64 ch1 0.03 ch2 10.90 ch3 0.17 ch4 42.68 ch5 49.41 Time for epoch 129 is 37.23751902580261 sec\n",
      "39400 [D real acc: 96.61%] [D fake acc: 95.79%] [G acc: 4.21%] \n",
      "39500 [D real acc: 96.62%] [D fake acc: 95.80%] [G acc: 4.20%] \n",
      "39600 [D real acc: 96.62%] [D fake acc: 95.81%] [G acc: 4.19%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 17.80 ch1 0.03 ch2 11.31 ch3 0.16 ch4 35.21 ch5 42.27 Time for epoch 130 is 37.39443111419678 sec\n",
      "39700 [D real acc: 96.63%] [D fake acc: 95.82%] [G acc: 4.18%] \n",
      "39800 [D real acc: 96.64%] [D fake acc: 95.83%] [G acc: 4.17%] \n",
      "39900 [D real acc: 96.65%] [D fake acc: 95.84%] [G acc: 4.16%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 22.38 ch1 0.03 ch2 11.61 ch3 0.18 ch4 44.03 ch5 56.06 Time for epoch 131 is 39.9108030796051 sec\n",
      "40000 [D real acc: 96.65%] [D fake acc: 95.85%] [G acc: 4.15%] \n",
      "40100 [D real acc: 96.66%] [D fake acc: 95.86%] [G acc: 4.14%] \n",
      "40200 [D real acc: 96.67%] [D fake acc: 95.87%] [G acc: 4.13%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 16.65 ch1 0.04 ch2 11.37 ch3 0.14 ch4 31.39 ch5 40.30 Time for epoch 132 is 37.23028230667114 sec\n",
      "40300 [D real acc: 96.67%] [D fake acc: 95.87%] [G acc: 4.13%] \n",
      "40400 [D real acc: 96.68%] [D fake acc: 95.88%] [G acc: 4.12%] \n",
      "40500 [D real acc: 96.69%] [D fake acc: 95.89%] [G acc: 4.11%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 18.96 ch1 0.03 ch2 10.40 ch3 0.16 ch4 36.98 ch5 47.24 Time for epoch 133 is 37.2529034614563 sec\n",
      "40600 [D real acc: 96.69%] [D fake acc: 95.90%] [G acc: 4.10%] \n",
      "40700 [D real acc: 96.70%] [D fake acc: 95.91%] [G acc: 4.09%] \n",
      "40800 [D real acc: 96.71%] [D fake acc: 95.92%] [G acc: 4.08%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 18.52 ch1 0.04 ch2 11.42 ch3 0.17 ch4 36.36 ch5 44.61 Time for epoch 134 is 37.259624004364014 sec\n",
      "40900 [D real acc: 96.72%] [D fake acc: 95.93%] [G acc: 4.07%] \n",
      "41000 [D real acc: 96.72%] [D fake acc: 95.94%] [G acc: 4.06%] \n",
      "41100 [D real acc: 96.73%] [D fake acc: 95.94%] [G acc: 4.06%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 24.78 ch1 0.04 ch2 11.82 ch3 0.13 ch4 52.97 ch5 58.93 Time for epoch 135 is 37.292224645614624 sec\n",
      "41200 [D real acc: 96.74%] [D fake acc: 95.95%] [G acc: 4.05%] \n",
      "41300 [D real acc: 96.74%] [D fake acc: 95.96%] [G acc: 4.04%] \n",
      "41400 [D real acc: 96.75%] [D fake acc: 95.97%] [G acc: 4.03%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 27.01 ch1 0.04 ch2 11.29 ch3 0.14 ch4 59.35 ch5 64.25 Time for epoch 136 is 37.268128633499146 sec\n",
      "41500 [D real acc: 96.75%] [D fake acc: 95.98%] [G acc: 4.02%] \n",
      "41600 [D real acc: 96.76%] [D fake acc: 95.98%] [G acc: 4.02%] \n",
      "41700 [D real acc: 96.77%] [D fake acc: 95.99%] [G acc: 4.01%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 20.75 ch1 0.04 ch2 11.32 ch3 0.21 ch4 40.62 ch5 51.58 Time for epoch 137 is 37.26555252075195 sec\n",
      "41800 [D real acc: 96.78%] [D fake acc: 96.00%] [G acc: 4.00%] \n",
      "41900 [D real acc: 96.78%] [D fake acc: 96.01%] [G acc: 3.99%] \n",
      "42000 [D real acc: 96.79%] [D fake acc: 96.02%] [G acc: 3.98%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 23.65 ch1 0.04 ch2 12.12 ch3 0.22 ch4 49.64 ch5 56.21 Time for epoch 138 is 37.23175382614136 sec\n",
      "42100 [D real acc: 96.80%] [D fake acc: 96.03%] [G acc: 3.97%] \n",
      "42200 [D real acc: 96.80%] [D fake acc: 96.04%] [G acc: 3.96%] \n",
      "42300 [D real acc: 96.81%] [D fake acc: 96.04%] [G acc: 3.96%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 69260756994757964595200000.00 ch1 0.03 ch2 86.43 ch3 0.32 ch4 1897113965482074594869248.00 ch5 344406671008307758850113536.00 Time for epoch 139 is 37.33553171157837 sec\n",
      "42400 [D real acc: 96.82%] [D fake acc: 96.05%] [G acc: 3.95%] \n",
      "42500 [D real acc: 96.83%] [D fake acc: 96.06%] [G acc: 3.94%] \n",
      "42600 [D real acc: 96.83%] [D fake acc: 96.07%] [G acc: 3.93%] \n",
      "42700 [D real acc: 96.84%] [D fake acc: 96.08%] [G acc: 3.92%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 76221.47 ch1 0.04 ch2 10.52 ch3 0.33 ch4 130915.38 ch5 250181.10 Time for epoch 140 is 37.32122254371643 sec\n",
      "42800 [D real acc: 96.85%] [D fake acc: 96.09%] [G acc: 3.91%] \n",
      "42900 [D real acc: 96.85%] [D fake acc: 96.10%] [G acc: 3.90%] \n",
      "43000 [D real acc: 96.86%] [D fake acc: 96.11%] [G acc: 3.89%] \n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "305/305 [==============================] - 1s 4ms/step\n",
      "ws mean 52.20 ch1 0.04 ch2 13.27 ch3 0.41 ch4 116.94 ch5 130.32 Time for epoch 141 is 40.08477997779846 sec\n"
     ]
    }
   ],
   "source": [
    "history = train(dataset_with_cond, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "5.GAN.ipynb",
   "provenance": [
    {
     "file_id": "1NUVAcZshSKsDKHaeeNNI8ohcUJvqUKqO",
     "timestamp": 1623369938483
    },
    {
     "file_id": "1bthIWyh_69c0sa09VMrRj9mXKOPNu7sP",
     "timestamp": 1623365007022
    },
    {
     "file_id": "1L77q4mrDL6LbE2HURRWfH8vtKm8pUBzK",
     "timestamp": 1620124217177
    },
    {
     "file_id": "1640z4JoZlvsSRGao2KCW322_UwjcQaSp",
     "timestamp": 1620084259696
    },
    {
     "file_id": "1zwFy4NM6SiPYsXCIgVUOEhBXbJ6Rj1tV",
     "timestamp": 1620082260980
    },
    {
     "file_id": "1IbQMqLHIYF-vg6B4Abbobl4pkROWBwes",
     "timestamp": 1620082045291
    },
    {
     "file_id": "1fnbp6zHVBrdi1nCGkrokht8i-pAUfIyf",
     "timestamp": 1620056039573
    },
    {
     "file_id": "1WXvm9ORGBKSJCVApOV4gJIC0NC7OQFzX",
     "timestamp": 1619997366147
    },
    {
     "file_id": "1hYuZL48eIXUGFk2mPXxeUh610OkoOfmV",
     "timestamp": 1619991567406
    },
    {
     "file_id": "1SYhFD0Djg7etn9UB47zsjc948E5VxTFG",
     "timestamp": 1616868089323
    },
    {
     "file_id": "17CrRwBBNZfhpN3y5pk_dTt7PelHqfFSI",
     "timestamp": 1616535329540
    },
    {
     "file_id": "1eTiiJCqFmQvy8KLbd0FSI1WfweHUCz-w",
     "timestamp": 1616531331246
    },
    {
     "file_id": "1Tndd1egGbtLRTO0Hnz6QnI9XiV5nEZKq",
     "timestamp": 1616528772133
    },
    {
     "file_id": "1kTX59Ymn4DGGgjVVQTt7ocE_oy5Sanpx",
     "timestamp": 1616281970086
    },
    {
     "file_id": "1kPO5iwHQPVcMuTc_Tn5JcSIRJ4hNrWjH",
     "timestamp": 1616181812747
    },
    {
     "file_id": "1nkcov8gu5MJRqWxL1awc78jThGTXsTyZ",
     "timestamp": 1616013741366
    },
    {
     "file_id": "13iHBeXIFuSw6-EvChxlqiveFVFurjENx",
     "timestamp": 1615923191272
    },
    {
     "file_id": "1q1UXZxrBrZdwYFvuOtkaRAnqykzUqK1-",
     "timestamp": 1615843147388
    },
    {
     "file_id": "1NUjBm8LUmJ5_Cu3ithC2JLJ4aFAWFEm2",
     "timestamp": 1615585196418
    },
    {
     "file_id": "1Y8oTevpUwSdSV3oCdx_e37mkhaxPzrGf",
     "timestamp": 1615506244659
    }
   ]
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
